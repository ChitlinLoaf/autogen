{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engaging with Multimodal Models: GPT-4V in AutoGen\n",
    "\n",
    "In AutoGen, leveraging multimodal models can be done through two different methodologies:\n",
    "1. **MultimodalAgent**: Supported by GPT-4V and other LMMs, this agent is endowed with visual cognitive abilities, allowing it to engage in interactions comparable to those of other ConversableAgents.\n",
    "2. **VisionCapability**: For LLM-based agents lacking inherent visual comprehension, we introduce vision capabilities by converting images into descriptive captions.\n",
    "\n",
    "This guide will delve into each approach, providing insights into their application and integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before everything starts, install AutoGen with the `lmm` option\n",
    "\n",
    "Install `pyautogen`:\n",
    "```bash\n",
    "pip install \"pyautogen[lmm]>=0.2.22\"\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](/docs/installation/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from PIL import Image\n",
    "from termcolor import colored\n",
    "import numpy as np\n",
    "\n",
    "import autogen\n",
    "from autogen.code_utils import content_str\n",
    "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.capabilities.vision_capability import VisionCapability\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "from autogen.agentchat.contrib.img_utils import get_pil_image, pil_to_data_uri, AGImage, get_image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_4v = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-vision-preview\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config_list_4v should be something like:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        'model': 'gpt-4-vision-preview', \n",
    "        'api_key': 'your-api-key'\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE!!! It is important to have the following parameters setup this way, otherwise the\n",
    "# GPT-4V client might crash. Because GPT-4v does not not accept JSON objects or function calling.\n",
    "# The max_image_size should be 10 for Azure OpenAI API, but could be more than 10 if using OpenAI.\n",
    "\n",
    "gpt4v_llm_config = {\n",
    "    \"config_list\": config_list_4v,\n",
    "    \"cache_seed\": 42,\n",
    "    \"vision_model\": True,\n",
    "    \"json_object\": False,\n",
    "    \"tool_call\": False,\n",
    "    \"max_num_image\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to image-explainer):\n",
      "\n",
      "hi\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer\u001b[0m (to User_proxy):\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'hi', 'role': 'assistant'}, {'content': 'Hello! How can I assist you today?', 'role': 'user'}], summary='Hello! How can I assist you today?', cost=({'total_cost': 0.00046, 'gpt-4-1106-vision-preview': {'cost': 0.00046, 'prompt_tokens': 19, 'completion_tokens': 9, 'total_tokens': 28}}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_agent = ConversableAgent(\n",
    "    name=\"image-explainer\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config=gpt4v_llm_config,\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    human_input_mode=\"NEVER\",  # Try between ALWAYS or NEVER\n",
    "    max_consecutive_auto_reply=0,\n",
    "    code_execution_config={\n",
    "        \"use_docker\": False\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")\n",
    "\n",
    "\n",
    "# It can receive regular string message\n",
    "user_proxy.initiate_chat(image_agent, message=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to image-explainer):\n",
      "\n",
      "What's the breed of this dog?<PIL.Image.Image image mode=RGB size=1920x1080 at 0x7F3CE673F940>\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer\u001b[0m (to User_proxy):\n",
      "\n",
      "The dog in the image appears to be a Goldendoodle, which is a cross-breed dog obtained by breeding a Golden Retriever with a Poodle. The curly coat and the overall appearance suggest this mix, but without a genetic test, it's not possible to be 100% certain of the breed or mix of breeds.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': [\"What's the breed of this dog?\", <PIL.Image.Image image mode=RGB size=1920x1080 at 0x7F3CE673F940>], 'role': 'assistant'}, {'content': \"The dog in the image appears to be a Goldendoodle, which is a cross-breed dog obtained by breeding a Golden Retriever with a Poodle. The curly coat and the overall appearance suggest this mix, but without a genetic test, it's not possible to be 100% certain of the breed or mix of breeds.\", 'role': 'user'}], summary=\"The dog in the image appears to be a Goldendoodle, which is a cross-breed dog obtained by breeding a Golden Retriever with a Poodle. The curly coat and the overall appearance suggest this mix, but without a genetic test, it's not possible to be 100% certain of the breed or mix of breeds.\", cost=({'total_cost': 0.013810000000000001, 'gpt-4-1106-vision-preview': {'cost': 0.013810000000000001, 'prompt_tokens': 1150, 'completion_tokens': 77, 'total_tokens': 1227}}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    image_agent,\n",
    "    message=[\n",
    "        \"What's the breed of this dog?\",\n",
    "        AGImage(\"https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Write a poet for my image<PIL.Image.Image image mode=RGB size=1920x1080 at 0x7F3CDBB40190>\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer-1\u001b[0m (to chat_manager):\n",
      "\n",
      "Beneath the vast canvas of sky's endless blue,\n",
      "A tranquil sea of green stretches into view.\n",
      "Whispers of wind play in fields so wide,\n",
      "Where secrets and dreams in blades abide.\n",
      "\n",
      "The trees, tall sentinels, guard this serene scene,\n",
      "Their leaves casting shadows, a dance so serene.\n",
      "Their branches reach out, as if to embrace,\n",
      "The warmth of the sun, and the wind's gentle grace.\n",
      "\n",
      "Amidst this expanse, a path carved with care,\n",
      "Winding and narrow, as if leading to where\n",
      "The horizon kisses the earth's tender lip,\n",
      "Inviting the soul on a whimsical trip.\n",
      "\n",
      "The clouds above drift, like thoughts passing by,\n",
      "Painting tales of old in the theater of the sky.\n",
      "Each one a story, a moment in flight,\n",
      "Set against the day, and the approaching night.\n",
      "\n",
      "In this image captured, a stillness so rare,\n",
      "A piece of the planet, untouched by despair.\n",
      "A testament to beauty where the earth gently sighs,\n",
      "In the harmonious chorus 'neath the watchful skies.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer-2\u001b[0m (to chat_manager):\n",
      "\n",
      "As an AI language model, I don't have eyes or the ability to see images, including the one you mentioned (PIL.Image.Image image mode=RGB size=1920x1080 at 0x7F3CDBB40190). However, I can generate a general poem that might suit a variety of images. If you provide me with a description or context of the image, I can write a more specific poem tailored to your image's details. Here's a general poem for you:\n",
      "\n",
      "In hues that blend and swirl so bright,\n",
      "The canvas speaks in morning's light.\n",
      "A vision wide and splendid vast,\n",
      "With memories of the timeless past.\n",
      "\n",
      "An endless sky, a subtle grace,\n",
      "A tranquil and secluded place.\n",
      "Colors bloom and stretch in space,\n",
      "Harmonizing with such delicate lace.\n",
      "\n",
      "Nature's brush, oh so divine,\n",
      "Crafting scenes that intertwine.\n",
      "Every pixel, shade, and line,\n",
      "Within your frame, doth perfectly align.\n",
      "\n",
      "A snapshot of life's grand array,\n",
      "Captured in your frame to stay.\n",
      "A single moment, held at bay,\n",
      "To inspire hearts, come what may.\n",
      "\n",
      "In your borders, stories told,\n",
      "Of silent whispers, new and old.\n",
      "A sacred place, a hand to hold,\n",
      "In your image, the world unfolds.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': ['Write a poet for my image', <PIL.Image.Image image mode=RGB size=1920x1080 at 0x7F3CDBB40190>], 'role': 'assistant'}, {'content': \"Beneath the vast canvas of sky's endless blue,\\nA tranquil sea of green stretches into view.\\nWhispers of wind play in fields so wide,\\nWhere secrets and dreams in blades abide.\\n\\nThe trees, tall sentinels, guard this serene scene,\\nTheir leaves casting shadows, a dance so serene.\\nTheir branches reach out, as if to embrace,\\nThe warmth of the sun, and the wind's gentle grace.\\n\\nAmidst this expanse, a path carved with care,\\nWinding and narrow, as if leading to where\\nThe horizon kisses the earth's tender lip,\\nInviting the soul on a whimsical trip.\\n\\nThe clouds above drift, like thoughts passing by,\\nPainting tales of old in the theater of the sky.\\nEach one a story, a moment in flight,\\nSet against the day, and the approaching night.\\n\\nIn this image captured, a stillness so rare,\\nA piece of the planet, untouched by despair.\\nA testament to beauty where the earth gently sighs,\\nIn the harmonious chorus 'neath the watchful skies.\", 'name': 'image-explainer-1', 'role': 'user'}, {'content': \"As an AI language model, I don't have eyes or the ability to see images, including the one you mentioned (PIL.Image.Image image mode=RGB size=1920x1080 at 0x7F3CDBB40190). However, I can generate a general poem that might suit a variety of images. If you provide me with a description or context of the image, I can write a more specific poem tailored to your image's details. Here's a general poem for you:\\n\\nIn hues that blend and swirl so bright,\\nThe canvas speaks in morning's light.\\nA vision wide and splendid vast,\\nWith memories of the timeless past.\\n\\nAn endless sky, a subtle grace,\\nA tranquil and secluded place.\\nColors bloom and stretch in space,\\nHarmonizing with such delicate lace.\\n\\nNature's brush, oh so divine,\\nCrafting scenes that intertwine.\\nEvery pixel, shade, and line,\\nWithin your frame, doth perfectly align.\\n\\nA snapshot of life's grand array,\\nCaptured in your frame to stay.\\nA single moment, held at bay,\\nTo inspire hearts, come what may.\\n\\nIn your borders, stories told,\\nOf silent whispers, new and old.\\nA sacred place, a hand to hold,\\nIn your image, the world unfolds.\", 'name': 'image-explainer-2', 'role': 'user'}, {'content': '', 'role': 'assistant'}, {'content': '', 'role': 'assistant'}], summary='', cost=({'total_cost': 0.020849999999999997, 'gpt-4-1106-vision-preview': {'cost': 0.020849999999999997, 'prompt_tokens': 2037, 'completion_tokens': 16, 'total_tokens': 2053}}, {'total_cost': 0.020849999999999997, 'gpt-4-1106-vision-preview': {'cost': 0.020849999999999997, 'prompt_tokens': 2037, 'completion_tokens': 16, 'total_tokens': 2053}}), human_input=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent1 = ConversableAgent(\n",
    "    name=\"image-explainer-1\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config=gpt4v_llm_config,\n",
    "    system_message=\"Your image description is poetic and engaging.\",\n",
    ")\n",
    "agent2 = ConversableAgent(\n",
    "    name=\"image-explainer-2\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config=gpt4v_llm_config,\n",
    "    system_message=\"Your image description is factual and to the point.\",\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"Desribe image for me.\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    ")\n",
    "\n",
    "# We set max_round to 5\n",
    "groupchat = autogen.GroupChat(agents=[agent1, agent2, user_proxy], messages=[], max_round=5)\n",
    "group_chat_manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4v_llm_config)\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=[\n",
    "        \"Write a poet for my image\",\n",
    "        AGImage(\"https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
