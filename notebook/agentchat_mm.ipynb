{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engaging with Multimodal Models: GPT-4V in AutoGen\n",
    "\n",
    "In AutoGen, leveraging multimodal models can be done through two different methodologies:\n",
    "1. **MultimodalAgent**: Supported by GPT-4V and other LMMs, this agent is endowed with visual cognitive abilities, allowing it to engage in interactions comparable to those of other ConversableAgents.\n",
    "2. **VisionCapability**: For LLM-based agents lacking inherent visual comprehension, we introduce vision capabilities by converting images into descriptive captions.\n",
    "\n",
    "This guide will delve into each approach, providing insights into their application and integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before everything starts, install AutoGen with the `lmm` option\n",
    "\n",
    "Install `pyautogen`:\n",
    "```bash\n",
    "pip install \"pyautogen[lmm]>=0.2.22\"\n",
    "```\n",
    "\n",
    "For more information, please refer to the [installation guide](/docs/installation/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from termcolor import colored\n",
    "\n",
    "import autogen\n",
    "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
    "from autogen.agentchat.contrib.capabilities.vision_capability import VisionCapability\n",
    "from autogen.agentchat.contrib.img_utils import AGImage, get_image_data, get_pil_image, pil_to_data_uri\n",
    "from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent\n",
    "from autogen.code_utils import content_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list_4v = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\n",
    "        \"model\": [\"gpt-4-vision-preview\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config_list_4v should be something like:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        'model': 'gpt-4-vision-preview', \n",
    "        'api_key': 'your-api-key'\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE!!! It is important to have the following parameters setup this way, otherwise the\n",
    "# GPT-4V client might crash. Because GPT-4v does not not accept JSON objects or function calling.\n",
    "# The max_image_size should be 10 for Azure OpenAI API, but could be more than 10 if using OpenAI.\n",
    "\n",
    "gpt4v_llm_config = {\n",
    "    \"config_list\": config_list_4v,\n",
    "    \"cache_seed\": 42,\n",
    "    \"vision_model\": True,\n",
    "    \"json_object\": False,\n",
    "    \"tool_call\": False,\n",
    "    \"max_num_image\": 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to image-explainer):\n",
      "\n",
      "hi\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer\u001b[0m (to User_proxy):\n",
      "\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': 'hi', 'role': 'assistant'}, {'content': 'Hello! How can I assist you today?', 'role': 'user'}], summary='Hello! How can I assist you today?', cost=({'total_cost': 0.00046, 'gpt-4-1106-vision-preview': {'cost': 0.00046, 'prompt_tokens': 19, 'completion_tokens': 9, 'total_tokens': 28}}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_agent = ConversableAgent(\n",
    "    name=\"image-explainer\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config=gpt4v_llm_config,\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"A human admin.\",\n",
    "    human_input_mode=\"NEVER\",  # Try between ALWAYS or NEVER\n",
    "    max_consecutive_auto_reply=0,\n",
    "    code_execution_config={\n",
    "        \"use_docker\": False\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")\n",
    "\n",
    "\n",
    "# It can receive regular string message\n",
    "user_proxy.initiate_chat(image_agent, message=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tests.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(image_name))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Image.open(image_name)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtests.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/PIL/Image.py:3243\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3243\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3244\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3246\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tests.png'"
     ]
    }
   ],
   "source": [
    "\n",
    "image_name = \"../test/test_files/test_image.png\"\n",
    "\n",
    "print(os.path.exists(image_name))\n",
    "Image.open(image_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to image-explainer):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mimage-explainer\u001b[0m (to User_proxy):\n",
      "\n",
      "The dog in the image appears to be a Goldendoodle, which is a cross-breed dog obtained by breeding a Golden Retriever with a Poodle. The curly coat and the overall appearance suggest this mix, but without a genetic test, it's not possible to be 100% certain of the breed or mix of breeds.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': [\"What's the breed of this dog?\", <PIL.Image.Image image mode=RGB size=1920x1080 at 0x7F94CED703A0>], 'role': 'assistant'}, {'content': \"The dog in the image appears to be a Goldendoodle, which is a cross-breed dog obtained by breeding a Golden Retriever with a Poodle. The curly coat and the overall appearance suggest this mix, but without a genetic test, it's not possible to be 100% certain of the breed or mix of breeds.\", 'role': 'user'}], summary=\"The dog in the image appears to be a Goldendoodle, which is a cross-breed dog obtained by breeding a Golden Retriever with a Poodle. The curly coat and the overall appearance suggest this mix, but without a genetic test, it's not possible to be 100% certain of the breed or mix of breeds.\", cost=({'total_cost': 0.013810000000000001, 'gpt-4-1106-vision-preview': {'cost': 0.013810000000000001, 'prompt_tokens': 1150, 'completion_tokens': 77, 'total_tokens': 1227}}, {'total_cost': 0}), human_input=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    image_agent,\n",
    "    message=[\n",
    "        \"What's the breed of this dog?\",\n",
    "        AGImage(\"https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': ['Write a poet for my image', <PIL.Image.Image image mode=RGB size=1920x1080 at 0x7F94CECA9D90>], 'role': 'assistant'}, {'content': '', 'role': 'assistant'}, {'content': '', 'role': 'assistant'}, {'content': '', 'role': 'assistant'}, {'content': '', 'role': 'assistant'}], summary='', cost=({'total_cost': 0.007500000000000001, 'gpt-4-1106-vision-preview': {'cost': 0.007500000000000001, 'prompt_tokens': 726, 'completion_tokens': 8, 'total_tokens': 734}}, {'total_cost': 0.007500000000000001, 'gpt-4-1106-vision-preview': {'cost': 0.007500000000000001, 'prompt_tokens': 726, 'completion_tokens': 8, 'total_tokens': 734}}), human_input=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent1 = ConversableAgent(\n",
    "    name=\"image-explainer-1\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config=gpt4v_llm_config,\n",
    "    system_message=\"Your image description is poetic and engaging.\",\n",
    ")\n",
    "agent2 = ConversableAgent(\n",
    "    name=\"image-explainer-2\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    llm_config=gpt4v_llm_config,\n",
    "    system_message=\"Your image description is factual and to the point.\",\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"User_proxy\",\n",
    "    system_message=\"Desribe image for me.\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    ")\n",
    "\n",
    "# We set max_round to 5\n",
    "groupchat = autogen.GroupChat(agents=[agent1, agent2, user_proxy], messages=[], max_round=5)\n",
    "group_chat_manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4v_llm_config)\n",
    "\n",
    "user_proxy.initiate_chat(\n",
    "    group_chat_manager,\n",
    "    message=[\n",
    "        \"Write a poet for my image\",\n",
    "        AGImage(\"https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
